{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing necessary libraries\n"
      ],
      "metadata": {
        "id": "ii9sd-Nn_TTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk import pos_tag, word_tokenize\n"
      ],
      "metadata": {
        "id": "UMvRNmdk_Wng"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading necessary NLTK resources\n"
      ],
      "metadata": {
        "id": "FeOOYe46_YWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "L3KxSNJj_WjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample text"
      ],
      "metadata": {
        "id": "DXNU9Vic_apO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The leaves on the trees are falling. The children are playing with leaves in the park.\"\n"
      ],
      "metadata": {
        "id": "F_5JHYrp_WgO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizing the text into words\n"
      ],
      "metadata": {
        "id": "zoFDGkGn_cVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(text)\n"
      ],
      "metadata": {
        "id": "vVcVhtNo_WaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(text)"
      ],
      "metadata": {
        "id": "z6qyGsC3Zgfr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Stemming\n"
      ],
      "metadata": {
        "id": "TIXusxPl_ecC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "print(\"Stemmed Words: \", stemmed_words)"
      ],
      "metadata": {
        "id": "puov6nZD_WWF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad4e2865-ec7b-4c3a-c63d-4d59a7f15f70"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed Words:  ['the', 'leav', 'on', 'the', 'tree', 'are', 'fall', '.', 'the', 'children', 'are', 'play', 'with', 'leav', 'in', 'the', 'park', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "print(\"Stemmed Words:\" , stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDn6NXnoZloI",
        "outputId": "6b643e04-2a30-4d0c-ac74-06bd28266d70"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed Words: ['the', 'leav', 'on', 'the', 'tree', 'are', 'fall', '.', 'the', 'children', 'are', 'play', 'with', 'leav', 'in', 'the', 'park', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Lemmatization\n"
      ],
      "metadata": {
        "id": "gjDs9Pmc_gTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "dsqyCAUr_i3f"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "RotfREABZ6Ln"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to get part of speech tags compatible with WordNet\n"
      ],
      "metadata": {
        "id": "5t24WQ99_ksc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wordnet_pos(word):\n",
        "  tag = pos_tag([word])[0][1][0].upper()\n",
        "  tag_dict = {\"J\": wordnet.ADJ,\n",
        "              \"M\":wordnet.NOUN,\n",
        "              \"V\":wordnet.VERB,\n",
        "              \"R\":wordnet.ADV}\n",
        "  return tag_dict.get(tag,wordnet.NOUN)"
      ],
      "metadata": {
        "id": "pIGbAuH_Z-aj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wordnet_pos(word):\n",
        "    tag = pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "    return tag_dict.get(tag, wordnet.NOUN)"
      ],
      "metadata": {
        "id": "kgDD2hM__mhG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in words]\n",
        "print(\"Lemmatized Words: \", lemmatized_words)"
      ],
      "metadata": {
        "id": "6SgHxLJJ_tI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94dd0e7b-4428-47ab-fa2a-13ae98392726"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized Words:  ['The', 'leaf', 'on', 'the', 'tree', 'be', 'fall', '.', 'The', 'child', 'be', 'play', 'with', 'leaf', 'in', 'the', 'park', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_words = [lemmatizer.lemmatize(word,get_wordnet_pos(word)) for word in words]\n",
        "print(\"Lemmatized Words:\" , lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fprGxvZzalXY",
        "outputId": "8fc7e70b-288c-43fe-c934-ddd0d30b63e0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized Words: ['The', 'leaf', 'on', 'the', 'tree', 'be', 'fall', '.', 'The', 'child', 'be', 'play', 'with', 'leaf', 'in', 'the', 'park', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare original, stemmed, and lemmatized words\n"
      ],
      "metadata": {
        "id": "-ry54fxp_vfj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "gtKW6Vk4_Km2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84d95d00-7ca6-48f9-847a-04085a925291"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparison (Original, Stemmed, Lemmatized):\n",
            "The             -> the             -> The            \n",
            "leaves          -> leav            -> leaf           \n",
            "on              -> on              -> on             \n",
            "the             -> the             -> the            \n",
            "trees           -> tree            -> tree           \n",
            "are             -> are             -> be             \n",
            "falling         -> fall            -> fall           \n",
            ".               -> .               -> .              \n",
            "The             -> the             -> The            \n",
            "children        -> children        -> child          \n",
            "are             -> are             -> be             \n",
            "playing         -> play            -> play           \n",
            "with            -> with            -> with           \n",
            "leaves          -> leav            -> leaf           \n",
            "in              -> in              -> in             \n",
            "the             -> the             -> the            \n",
            "park            -> park            -> park           \n",
            ".               -> .               -> .              \n"
          ]
        }
      ],
      "source": [
        "comparison = list(zip(words, stemmed_words, lemmatized_words))\n",
        "print(\"\\nComparison (Original, Stemmed, Lemmatized):\")\n",
        "for original, stemmed, lemmatized in comparison:\n",
        "    print(f\"{original:15} -> {stemmed:15} -> {lemmatized:15}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import PorterStemmer\n"
      ],
      "metadata": {
        "id": "JzVXuFXr_yVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n"
      ],
      "metadata": {
        "id": "E3VD3gwV_4pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# List of words to stem\n"
      ],
      "metadata": {
        "id": "vN9xnoxH_5me"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"running\", \"jumps\", \"easily\", \"flying\"]\n"
      ],
      "metadata": {
        "id": "H0F65z_a_7GW"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize the stemmer"
      ],
      "metadata": {
        "id": "V3TrYFTr_9G8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n"
      ],
      "metadata": {
        "id": "JDAQYVcq_83z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: Stem each word and print the result\n"
      ],
      "metadata": {
        "id": "9gbg_-WF__cW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "\n",
        "print(\"Stemmed Words:\", stemmed_words)\n"
      ],
      "metadata": {
        "id": "n3ByrzKu_VAw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c933866-99dc-4df2-c77c-a4382df213c3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed Words: ['run', 'jump', 'easili', 'fli']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import WordNetLemmatizer and other necessary modules\n"
      ],
      "metadata": {
        "id": "9v_oNGh8ABmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk import pos_tag\n"
      ],
      "metadata": {
        "id": "FK5TnQicAGK7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# List of words to lemmatize\n"
      ],
      "metadata": {
        "id": "gqykQJbXAG7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"running\", \"jumps\", \"easily\", \"flying\"]\n"
      ],
      "metadata": {
        "id": "EhavRpJLAHzg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize the lemmatizer\n"
      ],
      "metadata": {
        "id": "JYJ0jgB_AIym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n"
      ],
      "metadata": {
        "id": "tNAQ7KTcAJtZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper function to get WordNet PoS tag\n"
      ],
      "metadata": {
        "id": "svvQAi75AKWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wordnet_pos(word):\n",
        "    tag = pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
        "    return tag_dict.get(tag, wordnet.NOUN)"
      ],
      "metadata": {
        "id": "gV61RG-3ALb0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: Lemmatize each word with PoS tag and print the result\n"
      ],
      "metadata": {
        "id": "8XXYt1N_ANNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in words]\n",
        "\n",
        "print(\"Lemmatized Words:\", lemmatized_words)\n"
      ],
      "metadata": {
        "id": "RLuE1fcyAEBW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25b21346-aa55-44e8-ad8a-247097b6ec6e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized Words: ['run', 'jump', 'easily', 'fly']\n"
          ]
        }
      ]
    }
  ]
}