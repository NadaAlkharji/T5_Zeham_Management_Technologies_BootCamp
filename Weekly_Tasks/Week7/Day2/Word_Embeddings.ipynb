{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihBopOobLb2q"
      },
      "source": [
        "## Introduction to Word Embeddings\n",
        "\n",
        "Word embeddings are a type of word representation that allows words to be represented as continuous vectors in a high-dimensional space. Unlike traditional representations like Bag of Words (BoW), word embeddings capture semantic meanings and relationships between words by placing similar words closer together in the vector space.\n",
        "\n",
        "### Key Concepts\n",
        "\n",
        "1. **Word Embedding**: A dense vector representation of a word where each dimension captures some aspect of its meaning.\n",
        "2. **Pre-trained Embeddings**: Embeddings learned from large corpora, such as Word2Vec, GloVe, and FastText.\n",
        "3. **Semantic Similarity**: Words with similar meanings will have similar embeddings, making it easier to perform tasks like word similarity and analogy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "J14EKzDQLg2f"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YBv0QyqLiSo"
      },
      "source": [
        " Load pre-trained Word2Vec model (Google News vectors)\n",
        "Note: This model is quite large. For demonstration, use a smaller or different model as needed.\n",
        " model = KeyedVectors.load_word2vec_format('path/to/GoogleNews-vectors-negative300.bin', binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Iyp8HlpbLmHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deb47344-0151-45e8-ce96-d1e3a6714270"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
          ]
        }
      ],
      "source": [
        "# For demonstration, we'll use a smaller pre-trained model available in gensim\n",
        "from gensim.downloader import load\n",
        "model = load('glove-wiki-gigaword-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xkigRBgHLoiP"
      },
      "outputs": [],
      "source": [
        "# Example words\n",
        "words = ['king', 'queen', 'man', 'woman']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xJngiE2qLqOr"
      },
      "outputs": [],
      "source": [
        "# Get embeddings\n",
        "embeddings = {word: model[word] for word in words}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "H01quYFFLWE0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6498dee3-daa9-4159-87d8-4cd7cac8409d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: king\n",
            "Embedding: [ 0.50451   0.68607  -0.59517  -0.022801  0.60046  -0.13498  -0.08813\n",
            "  0.47377  -0.61798  -0.31012  -0.076666  1.493    -0.034189 -0.98173\n",
            "  0.68229   0.81722  -0.51874  -0.31503  -0.55809   0.66421   0.1961\n",
            " -0.13495  -0.11476  -0.30344   0.41177  -2.223    -1.0756   -1.0783\n",
            " -0.34354   0.33505   1.9927   -0.04234  -0.64319   0.71125   0.49159\n",
            "  0.16754   0.34344  -0.25663  -0.8523    0.1661    0.40102   1.1685\n",
            " -1.0137   -0.21585  -0.15155   0.78321  -0.91241  -1.6106   -0.64426\n",
            " -0.51042 ]\n",
            "\n",
            "Word: queen\n",
            "Embedding: [ 0.37854    1.8233    -1.2648    -0.1043     0.35829    0.60029\n",
            " -0.17538    0.83767   -0.056798  -0.75795    0.22681    0.98587\n",
            "  0.60587   -0.31419    0.28877    0.56013   -0.77456    0.071421\n",
            " -0.5741     0.21342    0.57674    0.3868    -0.12574    0.28012\n",
            "  0.28135   -1.8053    -1.0421    -0.19255   -0.55375   -0.054526\n",
            "  1.5574     0.39296   -0.2475     0.34251    0.45365    0.16237\n",
            "  0.52464   -0.070272  -0.83744   -1.0326     0.45946    0.25302\n",
            " -0.17837   -0.73398   -0.20025    0.2347    -0.56095   -2.2839\n",
            "  0.0092753 -0.60284  ]\n",
            "\n",
            "Word: man\n",
            "Embedding: [-0.094386  0.43007  -0.17224  -0.45529   1.6447    0.40335  -0.37263\n",
            "  0.25071  -0.10588   0.10778  -0.10848   0.15181  -0.65396   0.55054\n",
            "  0.59591  -0.46278   0.11847   0.64448  -0.70948   0.23947  -0.82905\n",
            "  1.272     0.033021  0.2935    0.3911   -2.8094   -0.70745   0.4106\n",
            "  0.3894   -0.2913    2.6124   -0.34576  -0.16832   0.25154   0.31216\n",
            "  0.31639   0.12539  -0.012646  0.22297  -0.56585  -0.086264  0.62549\n",
            " -0.0576    0.29375   0.66005  -0.53115  -0.48233  -0.97925   0.53135\n",
            " -0.11725 ]\n",
            "\n",
            "Word: woman\n",
            "Embedding: [-1.8153e-01  6.4827e-01 -5.8210e-01 -4.9451e-01  1.5415e+00  1.3450e+00\n",
            " -4.3305e-01  5.8059e-01  3.5556e-01 -2.5184e-01  2.0254e-01 -7.1643e-01\n",
            "  3.0610e-01  5.6127e-01  8.3928e-01 -3.8085e-01 -9.0875e-01  4.3326e-01\n",
            " -1.4436e-02  2.3725e-01 -5.3799e-01  1.7773e+00 -6.6433e-02  6.9795e-01\n",
            "  6.9291e-01 -2.6739e+00 -7.6805e-01  3.3929e-01  1.9695e-01 -3.5245e-01\n",
            "  2.2920e+00 -2.7411e-01 -3.0169e-01  8.5286e-04  1.6923e-01  9.1433e-02\n",
            " -2.3610e-02  3.6236e-02  3.4488e-01 -8.3947e-01 -2.5174e-01  4.2123e-01\n",
            "  4.8616e-01  2.2325e-02  5.5760e-01 -8.5223e-01 -2.3073e-01 -1.3138e+00\n",
            "  4.8764e-01 -1.0467e-01]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Display embeddings\n",
        "for word, vector in embeddings.items():\n",
        "    print(f\"Word: {word}\\nEmbedding: {vector}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rKCazO0NLsOm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e55d621-1454-4c6b-8cc6-f62e228226fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('computers', 0.9165045022964478),\n",
              " ('software', 0.8814992904663086),\n",
              " ('technology', 0.852556049823761),\n",
              " ('electronic', 0.812586784362793),\n",
              " ('internet', 0.8060455322265625)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Find similar words\n",
        "similar_words = model.most_similar('computer', topn=5)\n",
        "\n",
        "# TODO:: Display similar words\n",
        "similar_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fkcpJPKvL43C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6922ce2e-a63f-4b86-816d-c9a6910d454e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('woman', 0.8947036266326904)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Solve analogy\n",
        "analogy_result = model.most_similar(positive=['queen', 'man'], negative=['king'], topn=1)\n",
        "\n",
        "# TODO:: Display result\n",
        "analogy_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "giOIJRU412Sd"
      },
      "outputs": [],
      "source": [
        "words = ['horse', 'donkey', 'camel', 'animal']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zVoUvU2M12Sd"
      },
      "outputs": [],
      "source": [
        "embeddings = {word: model[word] for word in words}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOpB11Nf12Se",
        "outputId": "87e7a7db-3e91-448d-e4b3-ff85b38ca232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: horse\n",
            "Embedding: [-0.20454    0.23321   -0.59158   -0.29205    0.29391    0.31169\n",
            " -0.94937    0.055974   1.0031    -1.0761    -0.0094648  0.18381\n",
            " -0.048405  -0.35717    0.26004   -0.41028    0.51489    1.2009\n",
            " -1.6136    -1.1003    -0.23455   -0.81654   -0.15103    0.37068\n",
            "  0.477     -1.7027    -1.2183     0.038898   0.23327    0.028245\n",
            "  1.6588     0.26703   -0.29938    0.99149    0.34263    0.15477\n",
            "  0.028372   0.56276   -0.62823   -0.67923   -0.163     -0.49922\n",
            " -0.8599     0.85469    0.75059   -1.0399    -0.11033   -1.4237\n",
            "  0.65984   -0.3198   ]\n",
            "\n",
            "Word: donkey\n",
            "Embedding: [ 0.28451  -1.0616    0.1381    0.14208   0.37307   0.40205  -0.52408\n",
            " -1.0584    0.71379  -0.15491  -0.13954   0.17014   0.20846   0.047252\n",
            "  0.34718  -0.21545  -0.08699   0.84779  -0.16995  -0.38202  -0.61229\n",
            " -0.34823  -0.10898   0.8679    1.072    -0.3608   -0.25251   0.50247\n",
            "  0.26133  -0.7241    0.54262   0.76691  -0.42548   1.4735    0.29613\n",
            "  0.63444   0.29252  -0.39962  -1.0632   -0.16554  -0.27009   0.58939\n",
            " -1.1831   -0.19949   0.41006  -0.21267  -0.10443  -1.3299    1.4444\n",
            " -0.74597 ]\n",
            "\n",
            "Word: camel\n",
            "Embedding: [-1.4417e-01 -4.9194e-01 -6.4290e-01 -9.8475e-02 -1.5894e-03  6.1682e-01\n",
            " -1.0983e+00 -9.3264e-01  1.8624e+00 -5.9683e-01  3.4774e-01  1.9142e-01\n",
            " -3.9594e-02 -5.4066e-01 -1.4208e-01  3.4118e-03 -2.7336e-01  7.4285e-01\n",
            " -9.3130e-01 -1.1773e+00 -2.4801e-01 -3.8554e-02  5.2436e-01  7.4463e-01\n",
            " -1.7686e-01 -8.1129e-01 -9.9230e-01  4.5682e-01  6.1241e-01  9.4613e-02\n",
            "  3.4189e-01  7.0487e-01 -6.7365e-01  1.6436e+00  4.0663e-01 -3.8789e-01\n",
            " -6.2926e-01 -2.0424e-01 -9.5539e-01  1.9019e-01  5.9161e-01  2.9000e-01\n",
            " -8.8210e-01  3.1598e-01  4.7993e-01 -2.9602e-01 -1.5669e-01 -9.9605e-01\n",
            " -1.7843e-01 -5.4153e-01]\n",
            "\n",
            "Word: animal\n",
            "Embedding: [ 0.49652   -0.65143   -1.0869    -0.10205    0.81724    0.923\n",
            " -0.56206   -1.3801     1.8115     0.068438   0.63906    0.24468\n",
            "  1.0308     0.10202    0.48498   -0.08387    0.61688    0.35812\n",
            " -0.75196   -0.3548    -0.14173    0.042311   0.42242   -0.21013\n",
            "  0.28935   -1.1214    -0.5278    -0.046298   0.064643  -0.43924\n",
            "  2.4004    -0.29715   -0.19765   -0.88725   -0.62955    0.64092\n",
            "  0.14741   -0.0089431  0.39569    0.060899  -0.33917   -0.15897\n",
            "  0.22115    0.83813    1.6032    -0.010252  -0.36843   -0.32005\n",
            "  0.4658    -0.10813  ]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for word, vector in embeddings.items():\n",
        "    print(f\"Word: {word}\\nEmbedding: {vector}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhAGvmrI12Se",
        "outputId": "012f783e-27fc-4b96-8089-98744935e201"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('dog', 0.9218006134033203),\n",
              " ('rabbit', 0.8487821221351624),\n",
              " ('monkey', 0.8041081428527832),\n",
              " ('rat', 0.7891963124275208),\n",
              " ('cats', 0.7865270972251892)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "similar_words = model.most_similar('cat', topn=5)\n",
        "\n",
        "similar_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BI2MjwmF12Se",
        "outputId": "0c75d26d-1bc4-4e4d-fc91-dbe7433ecc8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('chance', 0.7787271738052368)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "analogy_result = model.most_similar(positive=['goal', 'ball'], negative=['goalkeeper'], topn=1)\n",
        "\n",
        "analogy_result"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}